{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# INM432 Big Data Coursework 2016/207 Part 2: Spakr Pipelines and Evaluation of Scaling of Algorithms\n",
    "\n",
    "### Team Members: Ryan Nazareth and Aimore Dutra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanRating 1.7741505662891406\n",
      "se_df DataFrame[se: double]\n",
      "meanSE 1.2542604431985964\n",
      "Root-mean-square error = 1.0005635545150617\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate() # create a SparkSession \n",
    "lines = spark.read.text(\"hdfs://saltdean/data/movielens/sample_movielens_ratings.txt\").rdd \n",
    "parts = lines.map(lambda row: row.value.split(\"::\"))\n",
    "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),rating=float(p[2]), timestamp=int(p[3])))\n",
    "ratings = spark.createDataFrame(ratingsRDD)\n",
    "ratings.createOrReplaceTempView('ratings') # register the DataFrame so that we can use it with Spark SQL.\n",
    "\n",
    "SQL1 = 'SELECT AVG(rating) FROM ratings'\n",
    "row = spark.sql(SQL1).collect()[0] # get the single row with the result\n",
    "\n",
    "meanRating = row['avg(rating)'] # access Row as a map \n",
    "print('meanRating',meanRating)\n",
    "\n",
    "se_rdd = test.rdd.map(lambda row: Row(se = pow(row['rating']-meanRating,2)) ) \n",
    "se_df = spark.createDataFrame(se_rdd) \n",
    "se_df.createOrReplaceTempView('se')\n",
    "print('se_df',se_df)\n",
    "SQL2 = 'SELECT AVG(se) FROM se'\n",
    "row = spark.sql(SQL2).collect()[0]\n",
    "meanSE = row['avg(se)'] # access Row as a map \n",
    "print('meanSE',meanSE)\n",
    "\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# TrainValidationSplit will try all combinations of values and determine best model using\n",
    "# the evaluator.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.regParam, [0.03,0.1,0.3]) \\\n",
    "    .addGrid(als.rank, [5,10,50]).build()\n",
    "    \n",
    "# In this case the estimator is simply the linear regression.\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "regEval = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "tvs = TrainValidationSplit(estimator=als,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=regEval,\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "model = tvs.fit(training)\n",
    "\n",
    "# # Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "\n",
    "rmse = regEval.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
