{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# INM432 Big Data Coursework 2017 (Part 2): \n",
    "\n",
    "# Movie Recommendations using the MovieLens Dataset in Spark \n",
    "\n",
    "### Team Members: Ryan Nazareth and Aimore Resende Riquetti Dutra \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1) Introduction\n",
    "With the advent of the internet connecting everything and everyone, it became easy to one access a large amount of information. However, the facility to reach so much data also brought some problems. Consumers have to deal with an immeasurable number of items, loosing their time trying to find what they look for.\n",
    "\n",
    "Hence, big companies that have an immensity of products in their database are keen on advertising their products in a smart way helping their clients to find what they want.\n",
    "\n",
    "Nowadays, Recommendation Systems are being developed to address this problem.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.1) Task\n",
    "\n",
    "Our task is to create a Recommender System that can suggest new movies to users based on their preferences (ratings).\n",
    "\n",
    "There are several possible approaches for the recommendation task [1]:\n",
    "\n",
    "##### 1) Recommend the most popular items\n",
    "##### 2) Use a classifier to make recommendation\n",
    "##### 3) Collaborative Filtering\n",
    "\n",
    "#### We chose the Collaborative Filtering technique because this method gives more personalization and makes a more efficient use of data.\n",
    "\n",
    "The Collaborative Filtering approach has two main types:\n",
    "* a) User to User\n",
    "* b) Item to Item\n",
    "\n",
    "Item-based most of the time tends to be more accurate and computationally cheaper. It also is more convenient for a company where they have less items than users and less dynamic than the number of users. [2]\n",
    "\n",
    "We are using User-based, because it is a simpler approach and the number of users do not change.\n",
    "\n",
    "\n",
    "\n",
    "#### References\n",
    "[1] https://www.analyticsvidhya.com/blog/2016/06/quick-guide-build-recommendation-engine-python/\n",
    "\n",
    "[2] Sarwar, B., Karypis, G., Konstan, J. and Riedl, J., 2001, April. Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th international conference on World Wide Web (pp. 285-295). ACM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.2) Dataset\n",
    "\n",
    "*Movies and most recently series have become a trend due to their current amazing quality and quantity at hand. Thanks to the advances in technology allowing them to be cheaper and quickly produced, there are millions of movies and series available.\n",
    "Not only more content is being created, but the existing ones are being stored. This has resulted in viewers having difficulties to find new video entertainment instances that they like.*\n",
    "\n",
    "\n",
    "\n",
    "The selected dataset for the coursework was the \"(ml-20m)\" from MovieLens, a movie recommendation service [1,2]. We made this choice because it has a lot of data and most importantly because it contains user ratings that allow us to use the Collaborative Filtering technique. The details of the dataset is below: \n",
    "\n",
    "- 27,278 movies (with 19 different Genres)\n",
    "- 138,493 users\n",
    "- 465,564 tag applications \n",
    "- and 20,000,263 ratings (from 1-5 stars)\n",
    "\n",
    "These data were created by  users between January 09, 1995 and March 31, 2015.\n",
    "\n",
    "The data are divided in six files, containing each:\n",
    "- genome-scores.csv: MovieID::TagId::relevance\n",
    "- genome-tags.csv:   TagId::Tag\n",
    "- links.csv:         MovieID::imdbID::tmdbID\n",
    "- movies.csv:        MovieID::Title::Genres\n",
    "- ratings.csv:       UserID::MovieID::Rating::Timestamp\n",
    "- tags.csv:          UserID::MovieID::Tag::Timestamp\n",
    "\n",
    "\n",
    "> #### References\n",
    "[1] F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872\n",
    "\n",
    ">[2] http://files.grouplens.org/datasets/movielens/ml-20m-README.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.3) Learning Algorithm - ALS\n",
    "\n",
    "Collaborative filtering is often used for recommender systems [1]. This is a group of techniques that aim to fill in the missing entries of a user-item association matrix or item-item. \"Spark.ml currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. Spark.ml uses the alternating least squares (ALS) algorithm to learn these latent factors.\" \n",
    "The implementation in Spark.ml has the following parameters:\n",
    "\n",
    "\"\n",
    "- **numBlocks** is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10).\n",
    "- **rank** is the number of latent factors in the model (defaults to 10).\n",
    "- **maxIter** is the maximum number of iterations to run (defaults to 10).\n",
    "- **regParam** specifies the regularization parameter in ALS (defaults to 1.0).\n",
    "- **implicitPrefs** specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n",
    "- **alpha** is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0).\n",
    "- **nonnegative** specifies whether or not to use nonnegative constraints for least squares (defaults to false).\"\n",
    "\n",
    "We will be focusing in the **rank** and the **maxIter** parameters. First because implicitPref, alpha, and nonnegative do not apply in our approach. Second, it would take too much time to do the training with many parameters. Third, there was no easy function which we could use to output the values for numBlocks and regParam.\n",
    "\n",
    "\n",
    "### Implicity vs Explicity\n",
    "We will utilize the explicity method since the dataset doesn't contain implicit feedback (e.g. views, clicks, purchases, likes, shares etc.).\n",
    "\n",
    "### Train-Validation Split\n",
    "\"In addition to CrossValidator Spark also offers TrainValidationSplit for hyper-parameter tuning. TrainValidationSplit only evaluates each combination of parameters once, as opposed to k times in the case of CrossValidator. It is therefore less expensive, but will not produce as reliable results when the training dataset is not sufficiently large.\" [2]\n",
    "\n",
    "\n",
    "\n",
    " #### References\n",
    "[1] https://spark.apache.org/docs/latest/ml-collaborative-filtering.html\n",
    "\n",
    "[2] https://spark.apache.org/docs/latest/ml-tuning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.4) Considerations\n",
    "Since we are using collaborative filtering algorithm to predict ratings and recommend movies, we do not have a requirement for working with **Feature Extractors, Transformers and Selectors**, since the algorithm only requires a user-item matrix and user ratings [1]. Therefore, we will focus more on the modeling and commenting on the results for different parameters. Also, at the end of this project we will use our trained system to recommend movies for a new user and print out the most relevant recommended movies based on his initial ratings.\n",
    "\n",
    "\n",
    "#### References\n",
    "[1]  https://spark.apache.org/docs/1.6.0/ml-features.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "# 2) Code\n",
    "\n",
    "\n",
    "## 2.1) Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|     50|   3.5|1112484580|\n",
      "|     1|    112|   3.5|1094785740|\n",
      "|     1|    151|   4.0|1094785734|\n",
      "|     1|    223|   4.0|1112485573|\n",
      "|     1|    253|   4.0|1112484940|\n",
      "|     1|    260|   4.0|1112484826|\n",
      "|     1|    293|   4.0|1112484703|\n",
      "|     1|    296|   4.0|1112484767|\n",
      "|     1|    318|   4.0|1112484798|\n",
      "|     1|    337|   3.5|1094785709|\n",
      "|     1|    367|   3.5|1112485980|\n",
      "|     1|    541|   4.0|1112484603|\n",
      "|     1|    589|   3.5|1112485557|\n",
      "|     1|    593|   3.5|1112484661|\n",
      "|     1|    653|   3.0|1094785691|\n",
      "|     1|    919|   3.5|1094785621|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import and Load Dataset\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "import numpy as np\n",
    "import math \n",
    "import time\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Load data from the path to a dataframe called \"ratings\"\n",
    "## Small Dataset\n",
    "##rating = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"hdfs://saltdean/data/movielens/ml-latest-small/ratings.csv\")\n",
    "## Large Dataset\n",
    "rating = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"hdfs://saltdean/data/movielens/ml-20m/ratings.csv\")\n",
    "# Check which features are present \n",
    "print(\"rating\")\n",
    "rating.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.2) Split Training  and Testing data in 80/20 ratio with the option of further reducing training set size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset data size:  19980310  rows\n",
      "training data size:  15986149  rows\n",
      "test data size:  3994161  rows\n"
     ]
    }
   ],
   "source": [
    "### Further reduction of the Dataset size\n",
    "#(rating, garbage) = rating.randomSplit([0.999, 0.001]) # ~ 99%\n",
    "#(rating, garbage) = rating.randomSplit([0.1, 0.9])     # ~ 10%\n",
    "#(rating, garbage) = rating.randomSplit([0.01, 0.99])   # ~ 1%\n",
    "#(rating, garbage) = rating.randomSplit([0.001, 0.999]) # ~ 0.1%\n",
    "# Print dataset size\n",
    "print('dataset data size: ', rating.count(),' rows') \n",
    "# --------------------------------------------------------------------------- #\n",
    "### Split the data into training (80%) and hold-out testing data (20%)\n",
    "(training, test) = rating.randomSplit([0.8, 0.2])\n",
    "# --------------------------------------------------------------------------- #\n",
    "### Reduce the training data set (*uncomment all to keep with the original size) \n",
    "# (training, garbage) = training.randomSplit([0.8, 0.2])   # ~50%\n",
    "# (training, garbage) = training.randomSplit([0.25, 0.75]) # ~25% \n",
    "# (training, garbage) = training.randomSplit([0.1, 0.9])   # ~10% \n",
    "# (training, garbage) = training.randomSplit([0.01, 0.99]) # ~1% \n",
    "# --------------------------------------------------------------------------- #\n",
    "# Print traindata size\n",
    "print('training data size: ',training.count(),' rows') \n",
    "# Print training data size\n",
    "print('test data size: ',test.count(),' rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Manipulation and Transformation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies\n",
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      " Training\n",
      "movielens_training data size:  15986149  rows\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|rating| timestamp|               title|              genres|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|   1009|     1|   3.5|1112486013|Escape to Witch M...|Adventure|Childre...|\n",
      "|   1079|     1|   4.0|1094785665|Fish Called Wanda...|        Comedy|Crime|\n",
      "|   1089|     1|   3.5|1112484669|Reservoir Dogs (1...|Crime|Mystery|Thr...|\n",
      "|   1090|     1|   4.0|1112485453|      Platoon (1986)|           Drama|War|\n",
      "|   1097|     1|   4.0|1112485701|E.T. the Extra-Te...|Children|Drama|Sc...|\n",
      "|    112|     1|   3.5|1094785740|Rumble in the Bro...|Action|Adventure|...|\n",
      "|   1193|     1|   3.5|1112484690|One Flew Over the...|               Drama|\n",
      "|   1196|     1|   4.5|1112484742|Star Wars: Episod...|Action|Adventure|...|\n",
      "|   1198|     1|   4.5|1112484624|Raiders of the Lo...|    Action|Adventure|\n",
      "|   1200|     1|   4.0|1112484560|       Aliens (1986)|Action|Adventure|...|\n",
      "|   1201|     1|   3.0|1112484642|Good, the Bad and...|Action|Adventure|...|\n",
      "|   1208|     1|   3.5|1112484815|Apocalypse Now (1...|    Action|Drama|War|\n",
      "|   1214|     1|   4.0|1094785977|        Alien (1979)|       Horror|Sci-Fi|\n",
      "|   1215|     1|   4.0|1094786082|Army of Darkness ...|Action|Adventure|...|\n",
      "|   1217|     1|   3.5|1112484810|          Ran (1985)|           Drama|War|\n",
      "|   1219|     1|   4.0|1094785994|       Psycho (1960)|        Crime|Horror|\n",
      "|   1222|     1|   3.5|1112484637|Full Metal Jacket...|           Drama|War|\n",
      "|   1240|     1|   4.0|1112485401|Terminator, The (...|Action|Sci-Fi|Thr...|\n",
      "|   1243|     1|   3.0|1112485567|Rosencrantz and G...|        Comedy|Drama|\n",
      "|   1246|     1|   3.5|1094785759|Dead Poets Societ...|               Drama|\n",
      "|   1249|     1|   4.0|1112485382|Femme Nikita, La ...|Action|Crime|Roma...|\n",
      "|   1258|     1|   4.0|1094785994| Shining, The (1980)|              Horror|\n",
      "|   1261|     1|   3.5|1094786113|Evil Dead II (Dea...|Action|Comedy|Fan...|\n",
      "|   1262|     1|   3.5|1112484735|Great Escape, The...|Action|Adventure|...|\n",
      "|   1266|     1|   4.0|1112485371|   Unforgiven (1992)|       Drama|Western|\n",
      "|   1278|     1|   4.0|1094785986|Young Frankenstei...|      Comedy|Fantasy|\n",
      "|   1291|     1|   3.5|1112485525|Indiana Jones and...|    Action|Adventure|\n",
      "|   1304|     1|   3.0|1094785720|Butch Cassidy and...|      Action|Western|\n",
      "|   1333|     1|   4.0|1112484990|   Birds, The (1963)|     Horror|Thriller|\n",
      "|   1348|     1|   3.5|1094786056|Nosferatu (Nosfer...|              Horror|\n",
      "|   1350|     1|   3.5|1094786158|    Omen, The (1976)|Horror|Mystery|Th...|\n",
      "|   1370|     1|   3.0|1094785764|   Die Hard 2 (1990)|Action|Adventure|...|\n",
      "|   1374|     1|   4.0|1094785746|Star Trek II: The...|Action|Adventure|...|\n",
      "|   1387|     1|   4.0|1112484913|         Jaws (1975)|       Action|Horror|\n",
      "|    151|     1|   4.0|1094785734|      Rob Roy (1995)|Action|Drama|Roma...|\n",
      "|   1525|     1|   3.0|1112486150|Warriors of Virtu...|Action|Adventure|...|\n",
      "|   1584|     1|   3.5|1094785656|      Contact (1997)|        Drama|Sci-Fi|\n",
      "|   1750|     1|   3.5|1112486201|     Star Kid (1997)|Adventure|Childre...|\n",
      "|   1848|     1|   3.5|1112486032|Borrowers, The (1...|Adventure|Childre...|\n",
      "|   1920|     1|   3.5|1112486098|Small Soldiers (1...|Animation|Childre...|\n",
      "|   1967|     1|   4.0|1112485739|    Labyrinth (1986)|Adventure|Fantasy...|\n",
      "|   1994|     1|   3.5|1094786087|  Poltergeist (1982)|     Horror|Thriller|\n",
      "|   1997|     1|   3.5|1094786034|Exorcist, The (1973)|      Horror|Mystery|\n",
      "|      2|     1|   3.5|1112486027|      Jumanji (1995)|Adventure|Childre...|\n",
      "|   2021|     1|   4.0|1112485929|         Dune (1984)|    Adventure|Sci-Fi|\n",
      "|   2100|     1|   4.0|1112485955|       Splash (1984)|Comedy|Fantasy|Ro...|\n",
      "|   2118|     1|   4.0|1094786092|Dead Zone, The (1...|            Thriller|\n",
      "|   2138|     1|   4.0|1112485789|Watership Down (1...|Adventure|Animati...|\n",
      "|   2140|     1|   4.0|1112485705|Dark Crystal, The...|   Adventure|Fantasy|\n",
      "|   2143|     1|   4.0|1112485951|       Legend (1985)|Adventure|Fantasy...|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "Type of each Column \n",
      "\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "\n",
      " Test\n",
      "movielens_test data size:  3994161  rows\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|rating| timestamp|               title|              genres|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|   1036|     1|   4.0|1112485480|     Die Hard (1988)|Action|Crime|Thri...|\n",
      "|   1080|     1|   3.5|1112485375|Monty Python's Li...|              Comedy|\n",
      "|   1136|     1|   3.5|1112484609|Monty Python and ...|Adventure|Comedy|...|\n",
      "|   1259|     1|   4.0|1112485440|  Stand by Me (1986)|     Adventure|Drama|\n",
      "|   1321|     1|   4.0|1094786062|American Werewolf...|Comedy|Horror|Thr...|\n",
      "|   1358|     1|   4.0|1112485419|  Sling Blade (1996)|               Drama|\n",
      "|   2174|     1|   4.0|1112485843|  Beetlejuice (1988)|      Comedy|Fantasy|\n",
      "|   2193|     1|   4.0|1112485753|       Willow (1988)|Action|Adventure|...|\n",
      "|    223|     1|   4.0|1112485573|       Clerks (1994)|              Comedy|\n",
      "|   2288|     1|   4.0|1094786077|   Thing, The (1982)|Action|Horror|Sci...|\n",
      "|   2291|     1|   4.0|1094785777|Edward Scissorhan...|Drama|Fantasy|Rom...|\n",
      "|   2716|     1|   3.5|1094786012|Ghostbusters (a.k...|Action|Comedy|Sci-Fi|\n",
      "|   2762|     1|   4.0|1112485367|Sixth Sense, The ...|Drama|Horror|Mystery|\n",
      "|   2872|     1|   4.0|1112485697|    Excalibur (1981)|   Adventure|Fantasy|\n",
      "|     29|     1|   3.5|1112484676|City of Lost Chil...|Adventure|Drama|F...|\n",
      "|   2918|     1|   3.5|1112485465|Ferris Bueller's ...|              Comedy|\n",
      "|   3030|     1|   3.0|1112484548|      Yojimbo (1961)|    Action|Adventure|\n",
      "|  31696|     1|   4.0|1112485748|  Constantine (2005)|Action|Fantasy|Ho...|\n",
      "|   3889|     1|   4.0|1112486138|Highlander: Endga...|Action|Adventure|...|\n",
      "|   3932|     1|   3.0|1094786172|Invisible Man, Th...|       Horror|Sci-Fi|\n",
      "|   3997|     1|   3.5|1112486192|Dungeons & Dragon...|   Adventure|Fantasy|\n",
      "|   4011|     1|   4.0|1112485406|       Snatch (2000)|Comedy|Crime|Thri...|\n",
      "|     47|     1|   3.5|1112484727|Seven (a.k.a. Se7...|    Mystery|Thriller|\n",
      "|   5039|     1|   4.0|1112485898| Dragonslayer (1981)|Action|Adventure|...|\n",
      "|   5171|     1|   4.0|1112486104|Time Machine, The...|Action|Adventure|...|\n",
      "|    541|     1|   4.0|1112484603| Blade Runner (1982)|Action|Sci-Fi|Thr...|\n",
      "|   5898|     1|   3.5|1112486002|Sword and the Sor...|Action|Adventure|...|\n",
      "|   5952|     1|   5.0|1112484619|Lord of the Rings...|   Adventure|Fantasy|\n",
      "|   6093|     1|   4.0|1112485713|Last Unicorn, The...|Animation|Childre...|\n",
      "|    653|     1|   3.0|1094785691|  Dragonheart (1996)|Action|Adventure|...|\n",
      "|   6755|     1|   3.5|1094786067| Bubba Ho-tep (2002)|       Comedy|Horror|\n",
      "|   6834|     1|   3.5|1112486060|Wilder Napalm (1993)|Comedy|Fantasy|Ro...|\n",
      "|   7001|     1|   3.5|1094786101|Invasion of the B...|Horror|Mystery|Sc...|\n",
      "|   7389|     1|   4.0|1112486045|One Million Years...|   Adventure|Fantasy|\n",
      "|   7482|     1|   3.0|1112484575|Enter the Dragon ...|        Action|Crime|\n",
      "|   8482|     1|   3.5|1112485781|Picture of Dorian...|Drama|Fantasy|Horror|\n",
      "|    924|     1|   3.5|1094785598|2001: A Space Ody...|Adventure|Drama|S...|\n",
      "|   1136|    10|   4.0| 943497986|Monty Python and ...|Adventure|Comedy|...|\n",
      "|   1198|    10|   4.0| 943497376|Raiders of the Lo...|    Action|Adventure|\n",
      "|   1221|    10|   5.0| 943497502|Godfather: Part I...|         Crime|Drama|\n",
      "|   1230|    10|   4.0| 943497554|   Annie Hall (1977)|      Comedy|Romance|\n",
      "|   1250|    10|   4.0| 943497180|Bridge on the Riv...| Adventure|Drama|War|\n",
      "|   3107|    10|   3.0| 943497376|    Backdraft (1991)|        Action|Drama|\n",
      "|    356|    10|   3.0| 943497122| Forrest Gump (1994)|Comedy|Drama|Roma...|\n",
      "|    858|    10|   5.0| 943497439|Godfather, The (1...|         Crime|Drama|\n",
      "|   1449|   100|   5.0| 865874297|Waiting for Guffm...|              Comedy|\n",
      "|    162|   100|   4.0| 835720999|        Crumb (1994)|         Documentary|\n",
      "|    194|   100|   3.0| 835720813|        Smoke (1995)|        Comedy|Drama|\n",
      "|    260|   100|   4.0| 865874456|Star Wars: Episod...|Action|Adventure|...|\n",
      "|    265|   100|   4.0| 835720189|Like Water for Ch...|Drama|Fantasy|Rom...|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "Type of each Column \n",
      "\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "\n",
      " All Dataset\n",
      "All Dataset size:  19980310  rows\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|rating| timestamp|               title|              genres|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|   1009|     1|   3.5|1112486013|Escape to Witch M...|Adventure|Childre...|\n",
      "|   1079|     1|   4.0|1094785665|Fish Called Wanda...|        Comedy|Crime|\n",
      "|   1089|     1|   3.5|1112484669|Reservoir Dogs (1...|Crime|Mystery|Thr...|\n",
      "|   1090|     1|   4.0|1112485453|      Platoon (1986)|           Drama|War|\n",
      "|   1097|     1|   4.0|1112485701|E.T. the Extra-Te...|Children|Drama|Sc...|\n",
      "|    112|     1|   3.5|1094785740|Rumble in the Bro...|Action|Adventure|...|\n",
      "|   1193|     1|   3.5|1112484690|One Flew Over the...|               Drama|\n",
      "|   1196|     1|   4.5|1112484742|Star Wars: Episod...|Action|Adventure|...|\n",
      "|   1198|     1|   4.5|1112484624|Raiders of the Lo...|    Action|Adventure|\n",
      "|   1200|     1|   4.0|1112484560|       Aliens (1986)|Action|Adventure|...|\n",
      "|   1201|     1|   3.0|1112484642|Good, the Bad and...|Action|Adventure|...|\n",
      "|   1208|     1|   3.5|1112484815|Apocalypse Now (1...|    Action|Drama|War|\n",
      "|   1214|     1|   4.0|1094785977|        Alien (1979)|       Horror|Sci-Fi|\n",
      "|   1215|     1|   4.0|1094786082|Army of Darkness ...|Action|Adventure|...|\n",
      "|   1217|     1|   3.5|1112484810|          Ran (1985)|           Drama|War|\n",
      "|   1219|     1|   4.0|1094785994|       Psycho (1960)|        Crime|Horror|\n",
      "|   1222|     1|   3.5|1112484637|Full Metal Jacket...|           Drama|War|\n",
      "|   1240|     1|   4.0|1112485401|Terminator, The (...|Action|Sci-Fi|Thr...|\n",
      "|   1243|     1|   3.0|1112485567|Rosencrantz and G...|        Comedy|Drama|\n",
      "|   1246|     1|   3.5|1094785759|Dead Poets Societ...|               Drama|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Manipulation of the Data\n",
    "\n",
    "# Load data from path to dataframe called \"movies\" (all the movies)\n",
    "movies = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"hdfs://saltdean/data/movielens/ml-20m/movies.csv\")\n",
    "# Check which features are present \n",
    "print(\"movies\")\n",
    "movies.show()\n",
    "\n",
    "# Join the columns of \"movies\" with \"training\" and \"test\" datasets into \"movielens_training\" and \"movielens_test\"\n",
    "movielens_training = training.join(movies, \"movieId\")\n",
    "movielens_test = test.join(movies, \"movieId\")\n",
    "\n",
    "# Cast data type from String to Integer and Double for training and test datasets\n",
    "movielens_training = movielens_training.withColumn(\"movieId\", training[\"movieId\"].cast(IntegerType()))\n",
    "movielens_training = movielens_training.withColumn(\"rating\", training[\"rating\"].cast(DoubleType()))\n",
    "movielens_training = movielens_training.withColumn(\"timestamp\", training[\"timestamp\"].cast(IntegerType()))\n",
    "movielens_training = movielens_training.withColumn(\"userId\", training[\"userId\"].cast(IntegerType()))\n",
    "\n",
    "movielens_test = movielens_test.withColumn(\"movieId\", test[\"movieId\"].cast(IntegerType()))\n",
    "movielens_test = movielens_test.withColumn(\"rating\", test[\"rating\"].cast(DoubleType()))\n",
    "movielens_test = movielens_test.withColumn(\"timestamp\", test[\"timestamp\"].cast(IntegerType()))\n",
    "movielens_test = movielens_test.withColumn(\"userId\", test[\"userId\"].cast(IntegerType()))\n",
    "\n",
    "# ----- Print the training -----\n",
    "print(\"\\n Training\")\n",
    "training_count = movielens_training.count()\n",
    "print('movielens_training data size: ',training_count,' rows') \n",
    "movielens_training.show(50)\n",
    "# Print the types used in each column\n",
    "print(\"Type of each Column \\n\")\n",
    "movielens_training.printSchema()\n",
    "\n",
    "# ----- Print the test -----\n",
    "print(\"\\n Test\")\n",
    "test_count=movielens_test.count()\n",
    "print('movielens_test data size: ',test_count,' rows') \n",
    "movielens_test.show(50)\n",
    "# Print the types used in each column\n",
    "print(\"Type of each Column \\n\")\n",
    "movielens_test.printSchema()\n",
    "\n",
    "# Create the whole dataset again with less data\n",
    "print(\"\\n All Dataset\")\n",
    "all_count = test_count+training_count\n",
    "print('All Dataset size: ',(all_count),' rows') \n",
    "movie_ratings = movielens_training.unionAll(movielens_test)\n",
    "movie_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.4) Training and Testing the System\n",
    "- Do a Grid Search to select the best model\n",
    "- Predict test data using the best model\n",
    "- Evaluate the best model's performance and time taken for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Training Algorithm (ALS)\n",
      "Create Parameter Grid Builder\n",
      "rank: 5\n",
      "maxIter: 5\n",
      "\n",
      "-----------\n",
      "Training Error (RMS) =  0.7965\n",
      "Training time:  3296.2835  seconds\n",
      "\n",
      "Test Error (RMS) =  0.8203\n",
      "Test time:  0.0774  seconds\n"
     ]
    }
   ],
   "source": [
    "## Create the recommender system \n",
    "\n",
    "print(\"Create Training Algorithm (ALS)\")\n",
    "# Create an Alternate Least Square learning algorithm (Estimator)\n",
    "als = ALS(rank=10, \n",
    "          maxIter=10,\n",
    "          userCol=\"userId\",   \n",
    "          itemCol=\"movieId\",  \n",
    "          ratingCol=\"rating\")\n",
    "### numBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10).\n",
    "### rank is the number of latent factors in the model (defaults to 10).\n",
    "### maxIter is the maximum number of iterations to run (defaults to 10).\n",
    "### regParam specifies the regularization parameter in ALS (defaults to 1.0).\n",
    "print(\"Create Parameter Grid Builder\")\n",
    "## Create a ParamGridBuilder to construct a grid of parameters to search over. (ParameterMaps)\n",
    "paramGrid = ParamGridBuilder().addGrid(als.rank, [5,10,20,30])\\\n",
    "                                 .addGrid(als.maxIter, [5,10,20,30])\\\n",
    "                                 .build()\n",
    "            \n",
    "## No Grid Search\n",
    "#paramGrid = ParamGridBuilder().build() # * UnComment this line and comment the block above to run quickly\n",
    "\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# In this case the estimator is simply the linear regression. (Evaluator)\n",
    "regEval = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "#### ------------------------ TRAINING ------------------------ ####\n",
    "# Get start time\n",
    "s=time.time() # training time\n",
    "\n",
    "# Train and Validate models\n",
    "tvs = TrainValidationSplit(estimator=als,\n",
    "                            estimatorParamMaps=paramGrid,\n",
    "                            evaluator=regEval,\n",
    "                            # 80% of the data will be used for training, 20% for validation.\n",
    "                            trainRatio=0.8, seed=5)\n",
    "\n",
    "# Run TrainValidationSplit to train and choose the best set of parameters.\n",
    "model = tvs.fit(movielens_training)\n",
    "\n",
    "# Get the best model parameters\n",
    "best_model = model.bestModel\n",
    "maxIter = (best_model\n",
    "    ._java_obj     # Get Java object\n",
    "    .parent()      # Get parent (ALS estimator)\n",
    "    .getMaxIter()) # Get best maxIter\n",
    "\n",
    "rank = best_model.rank # Get best rank\n",
    "print(\"rank:\", rank)\n",
    "print(\"maxIter:\", maxIter)\n",
    "print('\\n-----------')\n",
    "\n",
    "# Get end time\n",
    "e=time.time() # training time\n",
    "\n",
    "# Test the model's prediction in the hold-out Training data           \n",
    "predictions = best_model.transform(movielens_training)\n",
    "\n",
    "# Drop any rows with nan values from prediction (due to cold start problem)\n",
    "# predictions = predictions.dropna()\n",
    "predictions = predictions.fillna(0);\n",
    "\n",
    "# Evaluate the overall performance of the model by computing the Root-mean-square error (RMSE) on the Training data\n",
    "rmse = regEval.evaluate(predictions)\n",
    "print(\"Training Error (RMS) = \", round(rmse, 4))\n",
    "\n",
    "## Print the size of training data\n",
    "# print('Training data size: ',training.count(),' rows')  \n",
    "     \n",
    "# Print the time spent to train\n",
    "print('Training time: ',round(e-s, 4),' seconds')\n",
    "\n",
    "#### ------------------------ TESTING ------------------------ ####\n",
    "# Get relative time\n",
    "s=time.time() # testing time\n",
    "\n",
    "# Test the model's prediction in the hold-out Test data           \n",
    "predictions = best_model.transform(movielens_test)\n",
    "\n",
    "# Get end time\n",
    "e=time.time() # testing time\n",
    "\n",
    "# Drop or replace with 0 any rows with nan values from prediction (due to cold start problem)\n",
    "predictions = predictions.dropna()\n",
    "# predictions = predictions.fillna(0);\n",
    "               \n",
    "# Evaluate the overall performance of the model by computing the Root-mean-square error (RMSE) on the Test data\n",
    "rmse = regEval.evaluate(predictions)\n",
    "print('')\n",
    "print(\"Test Error (RMS) = \", round(rmse, 4))\n",
    "\n",
    "## Print the size of test data\n",
    "# print('Test data size: ',test.count(),' rows')  \n",
    "     \n",
    "# Print the time spent to test\n",
    "print('Test time: ',round(e-s, 4),' seconds')\n",
    "\n",
    "####------ Results for training and testing without Grid Search ------------------####\n",
    "## using default parameters for rank (10) and number of iterations(10) \n",
    "\n",
    "## Training data size: ~80,000 rows\n",
    "# Training Error (RMS) =  0.6382  || Test Error (RMS) =  1.1182\n",
    "# Training time:  10.497  seconds || Test time:  0.0601  seconds\n",
    "\n",
    "## Training data size: ~8,000 rows\n",
    "# Training Error (RMS) =  0.2326  || Test Error (RMS) =  2.8208\n",
    "# Training time:  7.6864  seconds || Test time:  0.0603  seconds\n",
    "    \n",
    "## Training data size: ~800 rows\n",
    "# Training Error (RMS) =   0.0547 || Test Error (RMS) =  3.7398\n",
    "# Training time:  6.492  seconds  || Test time:  0.0514  seconds\n",
    " \n",
    "## Training data size: ~80 rows\n",
    "# Training Error (RMS) =  0.0501  || Test Error (RMS) =  3.7025\n",
    "# Training time:  5.419  seconds  || Test time:  0.0504  seconds\n",
    "\n",
    "# As we can see the larger the dataset the more computational expensive it is. \n",
    "# The training error is low and testing error is high for small dataset (meaning overfitting). \n",
    "# When the dataset is large, the model generalizes better, reducing overfitting.\n",
    "# One important point is that, only when the data set is really big (around 80,000) \n",
    "# is when the model starts to having a good prediction\n",
    "\n",
    "# The Parameter Grid Search was applied twice on two different dataset sizes - 100,000 rows and 20 M rows\n",
    "# and the results are documented below:. \n",
    "\n",
    "# ----------- Smaller Dataset Param Grid -----------\n",
    "\n",
    "# Dataset size: 100,000 rows\n",
    "# 80:20 training:test split \n",
    "\n",
    "# best parameters: rank: 5, maxIter: 5\n",
    "# Training Error (RMS) =  0.6765    || Test Error (RMS) =  0.9161\n",
    "# Training time:  276.0033  seconds || Test time:  0.0602  seconds\n",
    "\n",
    "\n",
    "# ----------- Largest Dataset Param Grid -----------\n",
    "\n",
    "# dataset data size:  19,980,310  rows\n",
    "# training data size:  15,986,149  rows\n",
    "# test data size:  3,994,161  rows\n",
    "\n",
    "# best parameters: rank: 5, maxIter: 5\n",
    "# Training Error (RMS) =  0.7965        ||Test Error (RMS) =  0.8203\n",
    "# Training time:  3296.2835  seconds    ||Test time:  0.0774  seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.5) Adding a new user and recommending movies (Extra Work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations\n",
      "\n",
      "+-------+------+------+----------+--------------------+--------------------+----------+\n",
      "|movieId|userId|rating| timestamp|               title|              genres|prediction|\n",
      "+-------+------+------+----------+--------------------+--------------------+----------+\n",
      "|  81731| 48498|   5.0|1373330202|Pillars of the Ea...|Drama|Romance|Thr...| 5.7182674|\n",
      "|    527| 39635|   5.0| 847096841|Schindler's List ...|           Drama|War|  5.649589|\n",
      "|  27251| 48498|   5.0|1373331096|10th Kingdom, The...|Adventure|Comedy|...| 5.5801716|\n",
      "|  72641| 48498|   5.0|1373406791|Blind Side, The  ...|               Drama|  5.531981|\n",
      "|   2571|123907|   5.0|1283548725|  Matrix, The (1999)|Action|Sci-Fi|Thr...|  5.523856|\n",
      "|   1873| 23589|   5.0| 900448872|Mis√©rables, Les (...|Crime|Drama|Roman...| 5.4881315|\n",
      "|  55872| 48498|   5.0|1374118664|  August Rush (2007)|       Drama|Musical| 5.4828544|\n",
      "|   1291| 97286|   5.0| 965765499|Indiana Jones and...|    Action|Adventure| 5.4667387|\n",
      "|   2268|  3354|   5.0|1320127903|Few Good Men, A (...|Crime|Drama|Thriller| 5.4662714|\n",
      "|    593| 18519|   5.0| 836265116|Silence of the La...|Crime|Horror|Thri...|  5.459923|\n",
      "+-------+------+------+----------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Recommended Movies\n",
      "\n",
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|    Room, The (2003)|\n",
      "|Schindler's List ...|\n",
      "|10th Kingdom, The...|\n",
      "|Raiders of the Lo...|\n",
      "|Star Wars: Episod...|\n",
      "|And Your Mother T...|\n",
      "|  Matrix, The (1999)|\n",
      "|All Passion Spent...|\n",
      "|   Fight Club (1999)|\n",
      "|Rhyme & Reason (1...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Suggest movies to a new user\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Convert the whole ratings dataset into RDD\n",
    "movies_rdd = movie_ratings.rdd\n",
    "movies_rdd.take(10)\n",
    "\n",
    "# New user's ratings(userID, MovieID, rating)\n",
    "df =[(0,32,3),   # Twelve Monkeys\n",
    "     (0,589,5),  # Terminator 2\n",
    "     (0,50,4),   # Usual Suspects\n",
    "     (0,1080,4), # Monty Python \n",
    "     (0,1278,1), # Young Frankenstein\n",
    "     (0,1266,1), # Unforgiven \n",
    "     (0,1249,1), # Femme Nikita \n",
    "     (0,1090,1), # Platoon \n",
    "     (0,919,1) , # Wizard of Oz\n",
    "     (0,47,5)]   # Seven \n",
    "\n",
    "# Convert df1 to a dataframe\n",
    "df1 = sqlContext.createDataFrame(df)\n",
    "\n",
    "# Convert df1 to a RDD\n",
    "newuser_rdd = df1.rdd\n",
    "newuser_rdd.take(10)\n",
    "\n",
    "# Convert newuser_rdd[\"MovieID\"] to a list\n",
    "myRatedMovieIds = newuser_rdd.map(lambda x: x[1])\n",
    "newuser_list = myRatedMovieIds.take(11)\n",
    "\n",
    "# Get all movies that newuser didn't rate\n",
    "candidates_RDD = movies_rdd.map(lambda x: x if x[0] not in newuser_list else 0)\n",
    "\n",
    "# Filter the movies that the newuser already rated\n",
    "candidates_f_RDD = candidates_RDD.filter(lambda x: x is not 0)\n",
    "# candidates.take(30)\n",
    "\n",
    "## Transform candidates RDD to DataFrame\n",
    "candidadates_DF = sqlContext.createDataFrame(candidates_f_RDD)\n",
    "# cand.show() # uncomment to print\n",
    "\n",
    "## Apply the candidates into the best model predictor\n",
    "predictions = best_model.transform(candidadates_DF)\n",
    "\n",
    "## Drop Nans values\n",
    "predictions = predictions.dropna()\n",
    "# predictions.show() # uncomment to print\n",
    "\n",
    "# Sort by the higher predictions\n",
    "recommendations = predictions.sort(desc(\"prediction\"))\n",
    "\n",
    "# Removed duplicated movies\n",
    "rec = recommendations.dropDuplicates([\"movieId\"])\n",
    "\n",
    "# Sort again by higher predictions\n",
    "recommend = rec.sort(desc(\"prediction\"))\n",
    "\n",
    "# Print Recommendations\n",
    "print(\"\\nRecommendations\\n\")\n",
    "recommend.show(10)\n",
    "\n",
    "# Print only title of movies\n",
    "print(\"\\nRecommended Movies\\n\")\n",
    "recommend.select(\"title\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3) Conclusions and Discussions\n",
    "\n",
    "We implemented a user-item collaborative filtering approach which treats the values in the user-items matrix as explicit user preferences (i.e. ratings directly given by the user). The ALS algorithm in Spark decomposes the user-item matrix into a product of latent factor matrices which are then used for predicting ratings[1]. The Mlib library also provides an option for Implicit feedback to treat values in the user-item matrix implicitly as user preferences (i.e. clicks, views etc.) where the higher the number, the larger the level of confidence in user preferences [2]. Based on this information, latent factors are inferred. This is more computationally expensive than the explicit approach but is more accurate. \n",
    "\n",
    "We first trained and tested our model without grid search on varied size datasets, ranging from 80 to 80,000 rows. With smaller data set sizes (below 8000 rows), we can see the Root Mean Square Error(RMSE) on the training set is relatively low but the test RMSE is high (3.7).  this is due to overfitting. As the training set is increasing further upto 80,000 rows the training error increases and test error decreases to 1.1. \n",
    "\n",
    "We then implemented a parameter grid search approach on the entire smaller Movielens dataset (100,000 rows) and the largest dataset(20M rows, using the rank and the number of iterations as our machine learning parameters. The larger the rank, generally the better our model is, as more latent factors are used. However, the downside is the computational time required. We chose an arbitary range of values for our initial training parameters in our parameter grid. The parameters of the best model of our grid search were rank(5) and number of iterations(5). We used the RMSE as our evaluation metric on our training and test data sets. The test RMSE for the 20M dataset showed an improvement in accuracy relative to the smaller dataset (reduction in RMSE from 0.92 to 0.82). However, the downside was a large increase in computational time from approximately 5 minutes for the smaller dataset to 54 minutes for the largest dataset. \n",
    "\n",
    "For the last section, we have used our trained model to recommended additional movies for a new user based on ratings given for 10 movies. The new user has rated crime/action movies highly (5) and non-crime/action movies low. Using our trained model, the recommendation provides reasonable suggestions for alternative movies with crime/action genres. \n",
    "\n",
    "Therefore, we achieved a system that can recommend movies based on the user's preferences (ratings). Although this is an efficient way to predict non available ratings and therefore recommend products, there is still some issues which we came across in this work. Firstly, there is the problem of new users who have not rated the movies i.e. cold start problem[1]. This generated 'NaN; prediction estimates for these users and hence had to be removed from the dataset. Secondly, collaborative filtering only really has a good accuracy with larger training data set size. \n",
    "\n",
    "\n",
    "#### References\n",
    "\n",
    "[1] Zhou, Y., Wilkinson, D., Schreiber, R. and Pan, R., 2008, June. Large-scale parallel collaborative filtering for the netflix prize. In International Conference on Algorithmic Applications in Management (pp. 337-348). Springer Berlin Heidelberg.\n",
    "\n",
    "[2] Hu, Y., Koren, Y. and Volinsky, C., 2008, December. Collaborative filtering for implicit feedback datasets. In Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on (pp. 263-272). Ieee."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
